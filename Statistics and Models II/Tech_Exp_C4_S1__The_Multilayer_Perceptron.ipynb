{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tech Exp C4 S1: The Multilayer Perceptron.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNleI6Z7IeeRVDKgO5dDSAx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"vhe1yX4AMckE"},"source":["# Technology Explorers Course 4, Session 1: The Multilayer Perceptron\n","\n","**Instructor**: Wesley Beckner\n","\n","**Contact**: wesleybeckner@gmail.com\n","\n","<br>\n","\n","---\n","\n","<br>\n","\n","In this session we will introduce NEURAL NETWORKS! We'll cover the over arching concepts used to talk about network architecture as well as their building blocks.\n","\n","_images in this notebook borrowed from [Ryan Holbrook](https://mathformachines.com/)_\n","\n","<br>\n","\n","---\n","\n","<br>\n","\n","<a name='top'></a>\n","\n","# Contents\n","\n","* 1.0 [Preparing Environment and Importing Data](#x.0)\n","  * 1.0.1 [Import Packages](#x.0.1)\n","  * 1.0.2 [Load Dataset](#x.0.2)\n","* 1.1 [Neural Network Architectures](#x.1)\n","  * 1.1.1 [Input, Output, and Hidden Layers](#x.1.1)\n","  * 1.1.2 [Feed Forward](#x.1.2)\n","  * 1.1.3 [Recurrent](#x.1.3)\n","  * 1.1.4 [Convolutional](#x.1.4)\n","* 1.2 [Neural Network Building Blocks](#x.2)\n","  * 1.2.1 [Assigning Blame](#x.2.1)\n","  * 1.2.2 [Chain Rule](#x.2.2)\n","  * 1.2.3 [Back-Propagation](#x.2.3)\n","  * 1.2.4 [Maximum Likelihood Estimation](#x.2.4)\n","    * 1.2.4.1 [Linear Regression as Maximum Likelihood](#x.2.4.1)\n","  * 1.2.5 [Activation Functions](#x.2.5)\n","* 1.3 [Enrichment: Program Your Own Neural Network](#x.3)\n","  \n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"mNtJitcRW51Y"},"source":["<a name='x.0'></a>\n","\n","## 1.0 Preparing Environment and Importing Data\n","\n","[back to top](#top)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C3kYgV3LLGKJ","executionInfo":{"status":"ok","timestamp":1627940346645,"user_tz":420,"elapsed":10973,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"2a79ddd9-96fd-497a-ca80-bf1ed4f121c4"},"source":["!pip uninstall scikit-learn -y\n","\n","!pip install -U scikit-learn"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found existing installation: scikit-learn 0.22.2.post1\n","Uninstalling scikit-learn-0.22.2.post1:\n","  Successfully uninstalled scikit-learn-0.22.2.post1\n","Collecting scikit-learn\n","  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 1.8 MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Installing collected packages: threadpoolctl, scikit-learn\n","Successfully installed scikit-learn-0.24.2 threadpoolctl-2.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"chdcBoBL8SNm"},"source":["<a name='x.0.1'></a>\n","\n","### 1.0.1 Import Packages\n","\n","[back to top](#top)"]},{"cell_type":"code","metadata":{"id":"KtCyp8X9zjpF","executionInfo":{"status":"ok","timestamp":1627940350839,"user_tz":420,"elapsed":4198,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["from tensorflow import keras\n","from keras import backend as K\n","from tensorflow.keras import layers\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","import plotly.express as px\n","\n","from sklearn.impute import SimpleImputer\n","from copy import copy\n","sns.set()\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import make_column_transformer, make_column_selector\n","from sklearn import set_config\n","from sklearn.pipeline import make_pipeline\n","from sklearn.metrics import mean_squared_error\n","set_config(display='diagram')"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7vDY-8U8SWd"},"source":["<a name='x.0.1'></a>\n","\n","### 1.0.2 Load Dataset\n","\n","[back to top](#top)\n","\n","Before diving in I want to compare two methods of reading and preprocessing our data:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":135},"id":"AXSQeVAvKySD","executionInfo":{"status":"ok","timestamp":1627940351222,"user_tz":420,"elapsed":392,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"8ce65b1d-d534-40c9-b89f-e4d6196e9ee8"},"source":["# import wine data\n","wine = pd.read_csv(\"https://raw.githubusercontent.com/wesleybeckner/\"\\\n","      \"ds_for_engineers/main/data/wine_quality/winequalityN.csv\")\n","\n","# create X and y\n","X = wine.copy()\n","y = X.pop('quality')\n","\n","# split into train/test\n","X_train, X_test, y_train, y_test = train_test_split(X, y)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train)\n","\n","# the numerical values pipe\n","num_proc = make_pipeline(SimpleImputer(strategy='median'), # impute with median\n","                         StandardScaler()) # scale and center\n","\n","# the categorical values pipe\n","cat_proc = make_pipeline(\n","    SimpleImputer(strategy='constant', \n","                  fill_value='missing'), # impute with placeholder\n","    OneHotEncoder(handle_unknown='ignore')) # one hot encode\n","\n","# parallelize the two pipes\n","preprocessor = make_column_transformer((num_proc,\n","                                make_column_selector(dtype_include=np.number)),\n","                                       (cat_proc,\n","                                make_column_selector(dtype_include=object)))\n","\n","X_train_std = preprocessor.fit_transform(X_train) # fit_transform on train\n","X_test_std = preprocessor.transform(X_test) # transform test and validation\n","X_val_std = preprocessor.transform(X_val)\n","\n","y_train_std = np.log(y_train) # log output y\n","y_val_std = np.log(y_val) # log output y\n","y_test_std = np.log(y_test) # log output y\n","\n","preprocessor"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<style>#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef {color: black;background-color: white;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef pre{padding: 0;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-toggleable {background-color: white;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-estimator:hover {background-color: #d4ebff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-item {z-index: 1;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-parallel-item:only-child::after {width: 0;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-069f6ae6-e2d3-4cbd-988d-452411ada1ef\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"512c77a8-9287-404c-a0c2-c5792e63709c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"512c77a8-9287-404c-a0c2-c5792e63709c\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('pipeline-1',\n","                                 Pipeline(steps=[('simpleimputer',\n","                                                  SimpleImputer(strategy='median')),\n","                                                 ('standardscaler',\n","                                                  StandardScaler())]),\n","                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9250>),\n","                                ('pipeline-2',\n","                                 Pipeline(steps=[('simpleimputer',\n","                                                  SimpleImputer(fill_value='missing',\n","                                                                strategy='constant')),\n","                                                 ('onehotencoder',\n","                                                  OneHotEncoder(handle_unknown='ignore'))]),\n","                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9110>)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a2fce2cd-18ec-4d86-aa2b-e268c197a958\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"a2fce2cd-18ec-4d86-aa2b-e268c197a958\">pipeline-1</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9250></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"94da6033-e4ca-4b71-9f8d-456532255eff\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"94da6033-e4ca-4b71-9f8d-456532255eff\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='median')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8744f73f-6b1d-44d2-b4e1-6b25db6b4542\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8744f73f-6b1d-44d2-b4e1-6b25db6b4542\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"19be67c8-9d66-42c1-84f6-cf3e12acd361\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"19be67c8-9d66-42c1-84f6-cf3e12acd361\">pipeline-2</label><div class=\"sk-toggleable__content\"><pre><sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9110></pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9d76e5b4-8b5e-420f-8d08-757988451021\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9d76e5b4-8b5e-420f-8d08-757988451021\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5d9cc424-be38-4bcf-b501-70d71caf8071\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5d9cc424-be38-4bcf-b501-70d71caf8071\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["ColumnTransformer(transformers=[('pipeline-1',\n","                                 Pipeline(steps=[('simpleimputer',\n","                                                  SimpleImputer(strategy='median')),\n","                                                 ('standardscaler',\n","                                                  StandardScaler())]),\n","                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9250>),\n","                                ('pipeline-2',\n","                                 Pipeline(steps=[('simpleimputer',\n","                                                  SimpleImputer(fill_value='missing',\n","                                                                strategy='constant')),\n","                                                 ('onehotencoder',\n","                                                  OneHotEncoder(handle_unknown='ignore'))]),\n","                                 <sklearn.compose._column_transformer.make_column_selector object at 0x7f94300a9110>)])"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"wlj85iTSIwji"},"source":["<a name='x.1'></a>\n","\n","## 1.2 Neural Network Building Blocks\n","\n","[back to top](#top)"]},{"cell_type":"markdown","metadata":{"id":"b-5Mx4C8u5oy"},"source":["<a name='x.1.1'></a>\n","\n","### 1.1.1 The Perceptron\n","\n","[back to top](#top)\n","\n","The simplest unit of a neural network is the perceptron. Given an input vector $x$ and an output vector $y$, we can illustrate this like so:\n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/mfOlDR6.png\"></img>\n","</p>\n","\n","where $w$ is a weight applied to $x$ and $b$ is an unweighted term that we call the <i>bias</i>. We include a bias so that the perceptron is not entirely dependent on the input data. A neural network _learns_ by updating $w$ and $b$ so that it can accurately model $x$ to $y$. When we write out the perceptron mathematically we get the following:\n","\n","$$ y = xw+b $$\n","\n","which should look familiar! This is our equation for a linear function. In fact, we will see that a neural network is essentially many instances of linear regression along side, and being fed into, one another. \n","\n","Often, we will have not an input feature vector $x$ but an input feature matrix, $X$. We can update our schematic for a perceptron to account for this:\n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/vyXSnlZ.png\"></img>\n","</p>\n","\n","We can write the mathematical formula for this neuron as follows:\n","\n","$$ y =  x_2 w_2 + x_1 w_1 + x_0 w_0 + b $$\n","\n","In tensorflow/keras we can define this perceptron:"]},{"cell_type":"code","metadata":{"id":"QG0y0XItu_9J","executionInfo":{"status":"ok","timestamp":1627940351458,"user_tz":420,"elapsed":240,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Create a network with 1 linear unit\n","model = keras.Sequential([\n","    layers.Dense(units=1,  # number of units (the + filled circle above)\n","                 input_shape=[3]) # number of x_ (the x filled circle above)\n","])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2REdlnhH1dHS"},"source":["In order to build this single perceptron with keras, I had to use some additional language here: layers, dense, sequential. We'll explain what these are referring to in a moment. What I want to draw your attention to now, however, is that we tell `layers.Dense` that we want _1 unit_, the single perceptron, and `input_shape=[3]`, the number of features. Notice that `b` is automatically included without having it as a parameter. Just as we always have a y intercept in a linear model. \n","\n","After we introduce the other aspects of the neural network architecture, we will train a single perceptron model and compare it with a linear model, we will see that they are functionally no different."]},{"cell_type":"markdown","metadata":{"id":"hrtzdoY63JzU"},"source":["### 1.1.2 Exercise: Single Perceptron\n","\n","define a single perceptron that could be used to predict wine density from acidity. \n","\n","\n","Inpsect the weights.\n","\n","Use the untrained model to predict y and plot this against true y"]},{"cell_type":"code","metadata":{"id":"NNTUB3NZ2v1v","executionInfo":{"status":"ok","timestamp":1627940351460,"user_tz":420,"elapsed":31,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# Code cell for exercise 1.2.2\n","\n","# DECLARE MODEL\n","model = keras.Sequential([\n","                          \n","    ### YOUR CODE HERE ###\n","    \n","    \n","])"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"5yPd0JQ0yt2f","executionInfo":{"status":"ok","timestamp":1627940356286,"user_tz":420,"elapsed":180,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# model.weights"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me3pIoaHFWA1"},"source":["And now use the untrained model to predict `wine['density']` from `wine['fixed acidity']`"]},{"cell_type":"code","metadata":{"id":"EQYOBHnM3VM7","executionInfo":{"status":"aborted","timestamp":1627940351930,"user_tz":420,"elapsed":163,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# in the line below, use model.predict() and provide wine['fixed acidity'] as \n","# the input data to predict what wine['density'] will be\n","y_pred = # YOUR CODE HERE\n","\n","plt.plot(y_pred, wine['density'], ls='', marker='o')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"062Czp9-rBOi"},"source":["<a name='x.2'></a>\n","\n","## 1.2 Neural Network Architectures\n","\n","[back to top](#top)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"lPKG1QnNIq_l"},"source":["<a name='x.2.1'></a>\n","\n","###1.2.1 Neural Network Layers\n","\n","[back to top](#top)\n","\n","Now that we have the idea of the most basic building block of a neural network, we will start to discuss the larger architecture. The reason we focused on the lowest building block, is that neural networks are _modular_. They are made up of instances of these perceptrons or neurons. neurons in parallel make up a _layer_\n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/2MA4iMV.png\"></img>\n","<p>\n","\n","These layers feed into one another. When each node of a preceding layer is connected to every node of a following layer, we say they are _fully connected_ and the receiving layer is _a dense layer_. In a moment we will talk about input, output and hidden layers, for neural networks with three or more layers."]},{"cell_type":"markdown","metadata":{"id":"5QKiWYNwKAPE"},"source":["<a name='x.2.2'></a>\n","\n","### 1.2.2 The Activation Function\n","\n","[back to top](#top)\n","\n","It turns out that stringing together a bunch of linear functions, will still result in overall linear relationships. We need a way to break out of this. A neat trick is introduced at the output of each neuron. The output passes through an _activation function_. There are a handful of different activation functions used in practice, the most common is known as the _rectifier_ function:\n","\n","$$ max(f(x), 0) $$\n","\n","and the resulting node can be schematically drawn like this:\n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/eFry7Yu.png\"></img>\n","</p>\n","\n","with the inset of the summation node indicating that at a minimum the resultant y value is 0."]},{"cell_type":"markdown","metadata":{"id":"r6J9H0lAGLaD"},"source":["#### 1.2.2.1 Exercise: The Rectifier Function\n","\n","Write a function called `my_perceptron` that takes x, a length 2 array, as an input. Have your function return the maximum of $(0, w*x + b)$ where w is a length 2 weight vector."]},{"cell_type":"code","metadata":{"id":"Ukr1k7ZGGrD_","executionInfo":{"status":"aborted","timestamp":1627940351932,"user_tz":420,"elapsed":164,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["def my_perceptron(x):\n","  \"\"\"\n","  a simple 2 input feature perceptron with predefined weights, intercept, and \n","  a rectifier activation function\n","\n","  Parameters\n","  ----------\n","  x: array\n","    the input array of length 2\n","\n","  Returns\n","  rect: int\n","    the rectified output of the perceptron\n","  \"\"\"\n","\n","  # # define b, w, and y (y=mx+b)\n","  # w = \n","  # b = \n","  # y = \n","\n","  # # return the max of 0 and y\n","  # rect = \n","  return rect"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"99EI6eYzIRBA"},"source":["After you write your function make sure it returns 0 when the output of the linear component is negative."]},{"cell_type":"code","metadata":{"id":"5yyXqBSIG-wO","executionInfo":{"status":"aborted","timestamp":1627940351933,"user_tz":420,"elapsed":164,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["def test_zero_output():\n","  x = np.array([10,-10]) # 10 * 1 + (-10) * 2 + 1 = -11\n","  assert my_perceptron(x) == 0, \"The output is not zero when it should be!\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OsS4iRTIu1u","executionInfo":{"status":"aborted","timestamp":1627940351934,"user_tz":420,"elapsed":163,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["test_zero_output()\n","print(\"test passing\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lJJG5cakL9bT"},"source":["<a name='x.2.3'></a>\n","\n","### 1.2.3 Stacking Layers\n","\n","[back to top](#top)\n","\n","When we stack many layers together, we create what are traditionally regarded as neural networks. the first and last layers are called the _input_ and _output_ layers, while the inbetween layers are referred to as _hidden_ layers, since their outputs are not directly seen. Tradditionally, a neural network with three or more hidden layers is referred to as a _deep_ neural network.\n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/Y5iwFQZ.png\"></img\n","</p>\n","\n","Notice that in this schematic, the last node does not have an activation function. This is typical of a regression task. In a classification task, we might require an activation function here."]},{"cell_type":"markdown","metadata":{"id":"p6-UHfSQ3oVc"},"source":["<a name='x.2.2'></a>\n","\n","### 1.2.2 Building Sequential Neural Networks\n","\n","[back to top](#top)\n","\n","Now that we have the essential components of a neural network architecture, we can enter into the domain of overall naming conventions for architecure types. The classic neural network architecture is a _feed forward_ neural network, where every preceding layer feeds into the next layer. We will practice building that with keras."]},{"cell_type":"markdown","metadata":{"id":"V90sK92mNcNL"},"source":["### 1.2.5 Exercise: Building Sequential Layers\n","\n","In the cell bellow, use keras to build a 3-layer network with `activation='relu'` and 512 units. Create the output layer so that it can predict 1 continuous value."]},{"cell_type":"code","metadata":{"id":"-wTgl7X0NkQp","executionInfo":{"status":"ok","timestamp":1627940400172,"user_tz":420,"elapsed":340,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# Cell for exercise 1.1.5\n","\n","# DECLARE THE MODEL\n","\n","model = keras.Sequential([\n","                          \n","    ### YOUR CODE HERE ###\n","\n","    # the hidden ReLU layers\n","    layers.Dense(512),\n","    layers.Dense(512),\n","    layers.Dense(512),\n","\n","    # the linear output layer \n","    layers.Dense(1)\n","    \n","])"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ppKeNDLlRLYT"},"source":["### 1.2.6 Exercise: Other Activation Functions\n","\n","There are other activation functions we can use after the summation in a neural node. Use the code below to plot and inspect them!\n","\n","Pick one and do a quick google search on what that activation function's best use case is."]},{"cell_type":"code","metadata":{"id":"j0DzJmfKRCbv","executionInfo":{"status":"aborted","timestamp":1627940351939,"user_tz":420,"elapsed":167,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["import tensorflow as tf\n","\n","# YOUR CODE HERE: Change 'relu' to 'elu', 'selu', 'swish'... or something else\n","activation_layer = layers.Activation('relu')\n","\n","x = tf.linspace(-3.0, 3.0, 100)\n","y = activation_layer(x) # once created, a layer is callable just like a function\n","\n","plt.plot(x, y)\n","plt.xlim(-3, 3)\n","plt.xlabel(\"Input\")\n","plt.ylabel(\"Output\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XOQGi08Gur_g"},"source":["<a name='x.3'></a>\n","\n","## 1.3 Neural Network Training\n","\n","[back to top](#top)\n","\n","We've defined neural network architectures, now how do we train them? There are two main concepts here: the _loss function_ which we've encountered before, and the _optimizer_ the means by which we improve the loss function"]},{"cell_type":"markdown","metadata":{"id":"ERUFHizHT-n9"},"source":["<a name='x.3.1'></a>\n","\n","### 1.3.1 The Loss Function\n","\n","[back to top](#top)\n","\n","In previous sessions, we've envountered MSE:\n","\n","$$ MSE = \\frac{1}{N}\\sum{(y-\\hat{y})^2}$$\n","\n","<p align=center>\n","<img src=\"https://cdn.corporatefinanceinstitute.com/assets/Sum-of-Squares-1024x712.png\" width=400></img>\n","</p>\n","\n","Another common loss for neural networks is the mean absolute error (MAE):\n","\n","$$ MAE = \\frac{1}{N}\\sum{|y-\\hat{y}|}$$\n","\n","<p align=center>\n","<img src=\"https://cdn-media-1.freecodecamp.org/images/MNskFmGPKuQfMLdmpkT-X7-8w2cJXulP3683\" width=400></img>\n","</p>\n","\n","In anycase, the loss function describes the difference between the actual and predicted output of the model. The important thing to note, is that the weights in the neural network are systematically updated according to this loss function, they do this via an optimization algorithm."]},{"cell_type":"markdown","metadata":{"id":"4zE9cBS3nrSH"},"source":["<a name='x.3.2'></a>\n","\n","### 1.3.2 The Optimizer\n","\n","[back to top](#top)\n","\n","In order to update the neural network weights to improve the loss function, we require an algorithm. Virtually all available algorithms for this purpose fall within the family of _stochastic gradient descent_. This works essentially in these iterative steps:\n","\n","1. a subsample of the input data is passed through the network \n","2. a loss is computed\n","2. the weights are adjusted in a direction to improve the loss\n","\n","> The key here is in step 3. The brilliance of neural networks, is that the loss function is differentiable with respect to the weights in the network, and so the change in loss can be ascribed to certain weight changes. We refer to this as _assigning blame_ in the network, and it works through the mathematical _chain rule_ of differentiation. We won't go into great detail here, other than to make a nod to it, and that this algorithm (step 3) is referred to as _back propagation_. \n","\n","The three step process is repeated until a stop criteria is reached, the simplest being the loss stops improving above some threshold or a desired loss is achieved. \n","\n","<p align=center>\n","<img src=\"https://i.imgur.com/rFI1tIk.gif\"></img>\n","</p>\n","\n","In the above animation, the black line represents the output of the model, the red dots make up a _minibatch_ or simple a _batch_ while the opaque red dots represent the whole training dataset. Exposing the model to an entire round of the training data is referred to as an _epoch_. The training loss improves with additional rounds of trianing (middle panel) and the weights are adjusted to update the model (right panel).\n"]},{"cell_type":"markdown","metadata":{"id":"qvWwYKtFmt-Q"},"source":["### 1.3.3 Batches and Epochs\n","\n","An epoch is the number of times the model will see the entire training set\n","\n","A batch is the number of training samples the model will run before calculating a total error and updating its internal parameters. \n","\n","Variability of batch (from 1 sample all the way to the entire training set size) leads to different categorizations of the optimizer algorithm:\n","\n","* Batch Gradient Descent. Batch Size = Size of Training Set\n","* Stochastic Gradient Descent. Batch Size = 1\n","* Mini-Batch Gradient Descent. 1 < Batch Size < Size of Training Set\n","\n","We will visit additional details about batch and epochs in the next session when we discuss model evaluation."]},{"cell_type":"markdown","metadata":{"id":"lVd1TMcerkaJ"},"source":["<a name='x.3.3'></a>\n","\n","### 1.3.4 Learning Rate\n","\n","[back to top](#top)\n","\n","notice how in the above animation the model makes progressive steps toward a global optimum. The size of these steps is determined by the _learning rate_. You can think of it as the amount of improvement to make in the direction of steepest descent (the derivative of the loss function in regards to the changes in weights). Sometimes a large step size can result in stepping over crevices in the solution surface and getting stuck, while too small of step sizes can lead to a slow algorithm. Often the optimum learning rate is not obvious, luckily there are some optimizers that are self-calibrating in this regard. _Adam_ is one such optimizer available to us in keras. "]},{"cell_type":"code","metadata":{"id":"RxBq2QfwuFyh","executionInfo":{"status":"ok","timestamp":1627940406136,"user_tz":420,"elapsed":159,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# we can compile the model like so\n","model.compile(\n","    optimizer=\"adam\",\n","    loss=\"mae\",\n",")"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2p4qhOHy4BCP"},"source":["### 1.3.5 Exercise: Train your first Neural Networks\n","\n","[back to top](#top)\n","\n","We're going to train our first neural network.\n","\n","Take the model you created in exercise 1.2.5 and paste it in the cell below. Make sure that the `input_shape` of the first layer matches the number of features in `X_train_std`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qR725Pij03OC","executionInfo":{"status":"ok","timestamp":1627940694857,"user_tz":420,"elapsed":145,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"3182ef01-6be5-4df9-d977-b83078c50684"},"source":["X_train_std.shape[1]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["13"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"spB1UMIMuFOv","executionInfo":{"status":"ok","timestamp":1627940659614,"user_tz":420,"elapsed":155,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["# Cell for exercise 1.1.5\n","\n","# DECLARE THE MODEL\n","\n","model = keras.Sequential([\n","                          \n","    ### YOUR CODE HERE ###\n","\n","    # the hidden ReLU layers\n","    layers.Dense(512, input_shape=[X_train_std.shape[1]]),\n","    layers.Dense(512),\n","    layers.Dense(512),\n","\n","    # the linear output layer \n","    layers.Dense(1)\n","    \n","])"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZovXZPLdkSO"},"source":["Now we'll compile the model"]},{"cell_type":"code","metadata":{"id":"GU5e8QlfDm2v","executionInfo":{"status":"ok","timestamp":1627940660929,"user_tz":420,"elapsed":175,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}}},"source":["model.compile(\n","    optimizer='adam',\n","    loss='mse',\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4yYit0rRdmYr"},"source":["And then train for 10 epochs"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TjHiz9bBDovQ","executionInfo":{"status":"ok","timestamp":1627940667295,"user_tz":420,"elapsed":4241,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"b5958bab-1f65-4629-da36-8206e18cb5a2"},"source":["history = model.fit(\n","    X_train_std, y_train_std,\n","    validation_data=(X_val_std, y_val_std),\n","    batch_size=256,\n","    epochs=10,\n",")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","15/15 [==============================] - 1s 32ms/step - loss: 0.6261 - val_loss: 0.1552\n","Epoch 2/10\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0904 - val_loss: 0.0391\n","Epoch 3/10\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0410 - val_loss: 0.0300\n","Epoch 4/10\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0247 - val_loss: 0.0197\n","Epoch 5/10\n","15/15 [==============================] - 0s 25ms/step - loss: 0.0204 - val_loss: 0.0199\n","Epoch 6/10\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0192 - val_loss: 0.0195\n","Epoch 7/10\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0191 - val_loss: 0.0187\n","Epoch 8/10\n","15/15 [==============================] - 0s 22ms/step - loss: 0.0197 - val_loss: 0.0207\n","Epoch 9/10\n","15/15 [==============================] - 0s 24ms/step - loss: 0.0222 - val_loss: 0.0204\n","Epoch 10/10\n","15/15 [==============================] - 0s 23ms/step - loss: 0.0198 - val_loss: 0.0204\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zJhdp8txeRGv"},"source":["Let's take a look at our training history:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":361},"id":"c8w_bgj012Yl","executionInfo":{"status":"ok","timestamp":1627940941968,"user_tz":420,"elapsed":190,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"9e999648-9862-4b62-d8cb-6bfd7cb2de5d"},"source":["history_df"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>val_loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.581028</td>\n","      <td>0.097916</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.076502</td>\n","      <td>0.042938</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.029873</td>\n","      <td>0.022351</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.020602</td>\n","      <td>0.020168</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.022123</td>\n","      <td>0.022313</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.020971</td>\n","      <td>0.022476</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.022543</td>\n","      <td>0.019912</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.020645</td>\n","      <td>0.025689</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.020944</td>\n","      <td>0.023685</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.021303</td>\n","      <td>0.019592</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       loss  val_loss\n","0  0.581028  0.097916\n","1  0.076502  0.042938\n","2  0.029873  0.022351\n","3  0.020602  0.020168\n","4  0.022123  0.022313\n","5  0.020971  0.022476\n","6  0.022543  0.019912\n","7  0.020645  0.025689\n","8  0.020944  0.023685\n","9  0.021303  0.019592"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"1faQNrIeEFt4","executionInfo":{"status":"ok","timestamp":1627940999337,"user_tz":420,"elapsed":605,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"f38ff826-5a94-4dad-cde6-13f2cfd9f047"},"source":["# convert the training history to a dataframe\n","history_df = pd.DataFrame(history.history)\n","# use Pandas native plot method\n","fig, ax = plt.subplots(figsize=(10,5))\n","history_df['loss'].plot(ax=ax)\n","history_df['val_loss'].plot(ax=ax)\n","ax.set_ylim(0,.05)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.0, 0.05)"]},"metadata":{"tags":[]},"execution_count":25},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAl4AAAE1CAYAAAA2+u6CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxb9Z3v/9c52uXdjhc5djYgwZQEKEwoZQcTp63BDL0hbYZp720J0wsd2k47bTp3IARoO+l0KJSlnXJb7vADOtwMvUBMCCEsLdCWtjSsIQuJE8exbCd27MS2bEtH5/eHbCcmJJZjS7Lk9/PxyEOSdSx9xMey35zz1fkYtm3biIiIiEjCmakuQERERGSqUPASERERSRIFLxEREZEkUfASERERSRIFLxEREZEkUfASERERSRJnPBs1NDSwYsUKOjs7yc/PZ/Xq1cyaNWvENpZlceedd/LKK69gGAY33HADS5YsAeDee+/lscceo6SkBICPf/zjrFy5cmJfiYiIiMgkF1fwWrlyJcuWLaOuro6nnnqKW2+9lYcffnjENmvXrqWxsZENGzbQ2dnJ1VdfzXnnnUdFRQUAV199Nd/5zncm/hWIiIiIpIlRDzW2t7ezefNmamtrAaitrWXz5s10dHSM2G7dunUsWbIE0zQpLCykurqa9evXJ6ZqERERkTQ0avAKBoOUlpbicDgAcDgclJSUEAwGj9quvLx8+HYgEKClpWX49jPPPMOVV17Jl770JTZt2jRR9YuIiIikjbgONY7X5z73Ob7yla/gcrl47bXXuPHGG1m3bh0FBQXJeHoRERGRSWHU4BUIBGhtbcWyLBwOB5Zl0dbWRiAQOGq75uZmFixYAIzcA1ZcXDy83fnnn08gEGD79u0sXLgw7kIPHOghGk3cWMmiomza27sT9vjJYodD9P7XLbjPqsV16iWpLmfcNvypkRfeaOKOL38Ct+v4O2gzpYdTmXqY/tTD9Kb+jZ9pGhQUZB3z/lGDV1FREVVVVdTX11NXV0d9fT1VVVUUFhaO2G7x4sWsWbOGRYsW0dnZycaNG3n00UcBaG1tpbS0FID333+fvXv3Mnv27DG9kGjUTmjwGnqOdGebHiLdBzA6WnBkwOspzvPR2hFiZ3MXcyvzR90+E3o41amH6U89TG/qX2LFdajxtttuY8WKFTzwwAPk5uayevVqAJYvX87NN9/M/Pnzqaur46233mLRokUA3HTTTVRWVgJw11138d5772GaJi6Xix/+8Icj9oLJxDEMA8OXhx06mOpSJsTsQC4AO5sPxhW8REREJrO4gtdJJ53EmjVrjvr6gw8+OHzd4XCwatWqj/z+oaAmyWH4crFDXakuY0LkZrkpyvWyqyUzgqSIiExtOnN9BooFr8wJKrPLc9nZnDmvR0REpi4FrwxkZtChRoA5gVz2d/VxsHcg1aWIiIiMi4JXBhra42Xb0VSXMiFmB3IA2BXMnDApIiJTk4JXBjJ8uWBHob831aVMiJllORgGNAQPpboUERGRcVHwykCGL/ZJwGiGLLD3up2UT8uiQXu8REQkzSl4ZSDDnweQUeu8ZgdiC+xtW+eXERGR9KXglYGG9njZvZmxxwtiwas7FGZ/V1+qSxERETlhCl4ZyPRl3h6vOYMnUtXhRhERSWcKXpnI4wfDkVHBa3pxFk6HqeAlIiJpTcErAxmGieHLyZiz1wM4HSYzy7Jp0IlURUQkjSl4ZSjDl0c0g/Z4Acwuy2VX6yGsaGacn0xERKYeBa8MFdvjlWHBqzyXgXCU4P7MOD+ZiIhMPQpeGcrIsLFBcHiB/U6t8xIRkTSl4JWhYmODujLqvFclBT78HqcW2IuISNpS8MpQpj8XrAiEQ6kuZcIYhsHsQI4W2IuISNpS8MpQxtC5vHozK6TMLs+laV8PA2Er1aWIiIiMmYJXhsq0eY1DZgdyido2ja3dqS5FRERkzBS8MpSRgWevh1jwAi2wFxGR9KTglaEMXw5ARp1EFSA/20NBjoddCl4iIpKGFLwylOHNAYyM2+MFsdNKaI+XiIikIwWvDGWYDgxvdkYGr9nlubQdCNEdCqe6FBERkTFR8MpgmXgSVYDZZbHDqDrcKCIi6UbBK4MZ/tyMm9cIMLMsFwN0IlUREUk7Cl4ZzPDlYvdm1uJ6AL/XSVmRn4bgoVSXIiIiMiYKXhksUw81wuEF9pk0EklERDKfglcGM3y5EOnHDvenupQJNyuQy8GeAToOZt5rExGRzKXglcHMwbPXZ9q5vADmlMdem9Z5iYhIOlHwymDGcPDKvHBSUZyN02EoeImISFpR8MpgQ2ODMvGTjS6nSWVJjoKXiIikFQWvDJbJe7wAZgdyaGg5RDSqBfYiIpIeFLwymJHBa7wgNjC7f8Ai2NGb6lJERETiouCVwQyHEzxZ2L2ZucdreIF9c2a+PhERyTwKXhnO9OVm7B6v0kI/Po9D67xERCRtKHhlOMOXm7FrvEzDYFZZ7ESqIiIi6UDBK8MZvsyc1zhkdiCXprZuwhEr1aWIiIiMSsErwxkZfKgRYsHLito0tnWnuhQREZFRKXhlOMOXBwMh7MhAqktJCC2wFxGRdKLgleGGTynRdyjFlSRGQY6HvGw3DcHMfH0iIpJZFLwynDl49vpMXWAPMCeQq082iohIWlDwynCGP7NPogqxdV4tHb10h8KpLkVEROS4FLwy3PChxgw9iSrA7MF1Xh/sOZDiSkRERI5PwSvDDQWvjD6lRFkOANv3dKa4EhERkeNT8MpwhtMDLm9GH2r0e12UFvrZ1qg9XiIiMrkpeE0BmXz2+iFzAjm8t7ODUH8k1aWIiIgck4LXFDAVgtflZ1fSHRrgv36zI9WliIiIHJOC1xRg+vIyPnjNKc+l9oI5vPyXvXzQlLmHVUVEJL3FFbwaGhpYunQpNTU1LF26lF27dh21jWVZrFq1iurqaq644grWrFlz1DY7d+7kjDPOYPXq1eMuXOI3FfZ4AVy3+FQKcj38n/VbCEeiqS5HRETkKHEFr5UrV7Js2TKee+45li1bxq233nrUNmvXrqWxsZENGzbw+OOPc++999LU1DR8v2VZrFy5kurq6omrXuJi+HKx+7qxo5k9SNrvdfG3i+bRvL+HZ/+wO9XliIiIHGXU4NXe3s7mzZupra0FoLa2ls2bN9PR0TFiu3Xr1rFkyRJM06SwsJDq6mrWr18/fP/Pf/5zLrnkEmbNmjWxr0BGFTulhJ2xY4OOdMbJ01hYVUL973fRvL8n1eWIiIiM4Bxtg2AwSGlpKQ6HAwCHw0FJSQnBYJDCwsIR25WXlw/fDgQCtLS0ALBlyxZeffVVHn74YR544IETKrSoKPuEvm8siotzEv4cqdBdVkobkO+J4MnQ1zikuDiHry49ixtXv8hjL2znBzdegGkaqS5LxiBT34dTiXqY3tS/xBo1eI1XOBzmlltu4Qc/+MFweDsR7e3dRKP2BFY2UnFxDvv2ZeYeoUjYDUBHcxCnY1qKq0mcI3u45JKTeOjZLTzxwlYuOXN6iiuTeGXy+3CqUA/Tm/o3fqZpHHdn0ajBKxAI0NraimVZOBwOLMuira2NQCBw1HbNzc0sWLAAOLwHbN++fTQ2NnLDDTcAcPDgQWzbpru7mzvuuGM8r03iZA6NDZoCC+yHXLAgwO/fa2HNSzs48+Rp5Gd7Ul2SiIjI6Gu8ioqKqKqqor6+HoD6+nqqqqpGHGYEWLx4MWvWrCEajdLR0cHGjRupqamhvLyc119/nRdffJEXX3yRL37xi1x77bUKXUlk+PKAzB6U/WGGYfDFxacSjkR59PltqS5HREQEiPNTjbfddhuPPPIINTU1PPLII6xatQqA5cuX88477wBQV1dHRUUFixYt4tprr+Wmm26isrIycZVL/FxecHkJN7yB3T91FpyXFvqpu2AWb2zdx6Zt+1JdjoiICIZt24lbODWBtMZrfMIf/IG+lx/EzCvD96l/wMwuSnVJE+6jehixotz+f/5MT1+YO68/F58n4csaZRwy/X04FaiH6U39G7/R1njpzPVThOvkT+D71DeJdnfQ++QdWPunxnmunA6T//6pU+k81K9xQiIiknIKXlOIc/pp+Ov+FxgmvWt/QKTp3VSXlBRzynO5/OwKjRMSEZGUU/CaYhyFFfivvgUzp5jQsz8mvPWVVJeUFH990RyNExIRkZRT8JqCzKwC/Ff9E47yU+n7zS/o//P/I02W+p0wn8epcUIiIpJyCl5TlOH24fvUN3DOvZCBvzxF329+iR2NpLqshNI4IRERSTUFrynMMJ14L/4S7rOvJrLtFULr78YeCKW6rIT6fPVcPC4H/7F+C9EM38snIiKTj4LXFGcYBp6zr8Z78Zex9r5P79rvE+05kOqyEiYvy821l57M9qYufvtmc6rLERGRKUbBSwBwzbsQ36e+QfTgvtjpJjqaUl1SwlywIMCpM/JZ8/IHHDjUn+pyRERkClHwkmHOitPxX/ldsKP0Pv09Is3vp7qkhDg8TsjmsY0aJyQiIsmj4CUjOKbNjJ1uIquQ0LofEd7+u1SXlBAaJyQiIqmg4CVHMbOLYqebKJtL30s/p3/T2ow83UTNwhlUFGfzyPPbCPVn9ic6RURkclDwko9keLLwfeofcJ58HgN/eoL+V/4DO2qluqwJpXFCIiKSbApeckyGw4X30htwn1lLeMvLhJ67Bzvcl+qyJtSc8lwuP0fjhEREJDkUvOS4DMPAs/C/4bngi1hN79C79l+I9namuqwJdc1FcyjUOCEREUkCBS+Ji/u0S/HVfI1oZzO9T92J1Zk558Dyup1cp3FCIiKSBApeEjfnjDNjp5uIDND71PeIBLemuqQJo3FCIiKSDApeMiaO4tn4627B9OYQeuZfCe94PdUlTRiNExIRkURT8JIxM3OL8df9M46SOfS98FMG3no2I043oXFCIiKSaApeckIMbza+T38L55yF9L/+OP2/ewQ7mv4L0zVOSEREEknBS06Y4XTjvfwruBYsJvzeC/Q9fy92JL3DisYJiYhIIil4ybgYhon3E5/D88nriOx+k9761URDB1Nd1rhonJCIiCSKgpdMCPfp1XgXfZVo+x56n7qTaFdLqksaF40TEhGRRFDwkgnjmnU2/trvwECI3ifvxGr9INUlnTCNExIRkURQ8JIJ5Sg9GX/dP4Mni9761YQb3kh1SSdM44RERGSiKXjJhDPzSvHX/S/Mohn0PX8fA+8+n+qSTpjGCYmIyERS8JKEMH25+Gu/jXPWWfT/7lH6fv8rbDv9govX7eRvazROSEREJoaClySM4fTgrf4qro9VE37nOfo2PoAdGUh1WWO24CSNExIRkYmh4CUJZZgmnk/+DZ5PfI5Iw58JPfOv2H3dqS5rzDROSEREJoKClyScYRi4FyzGW30j1v4Gep66k+jBtlSXNSYaJyQiIhNBwUuSxjVnIb7PfBu77xC9T92J1bYz1SWNicYJiYjIeCl4SVI5y+aSVffP4HTTW/8vRHZvSnVJcRsxTuh5jRMSEZGxU/CSpDPzA/jrbsEsmE5ow08Y2PxiqkuK2/A4oW37+IvGCYmIyBgpeElKmP48/LUrcFQuoP/Vh+l//f+mzekmhsYJPapxQiIiMkYKXpIyhsuDb9HNuKouYeCtdfS9+HNsK5zqskalcUIiInKiFLwkpQzTgeeCL+Je+N+I7PgDoXU/wu6f/OfK0jghERE5EQpeknKGYeA5sxbvZX+H1foBvU9/j+ih/akua1QaJyQiImOl4CWThuvk8/B9+ltEew7Q++QdWPsn94gejRMSEZGxUvCSScVZXoX/qn8G00Hv2h8Q2fN2qks6Lo0TEhGRsVDwkknHUTgd/9W3YOaWEFp/NwNbfpPqko5L44RERCReCl4yKZlZBfiv/C6O6afR/9uH6P/zr7EnaajROCEREYmXgpdMWobbh2/x13HNu5CBvzxN38v/G9uanOfN0jghERGJh4KXTGqG6cRz0Zdwn/3XRLa/Rmj9j7EHelNd1lE0TkhEROKh4CWTnmEYeM6uw3vxl7Gat9D79PeJdnekuqyjaJyQiIiMRsFL0oZr3oX4PvUNoof20/vUHVjte1Jd0lGGxgk9smGrxgmJiMhRFLwkrTgrTsd/1T+BbdP79PeJNL2X6pJGGBon1NU9oHFCIiJylLiCV0NDA0uXLqWmpoalS5eya9euo7axLItVq1ZRXV3NFVdcwZo1a4bve+KJJ7jyyiupq6vjyiuv5OGHH56wFyBTj6NoRux0E9lFhJ69i/C211Jd0ggaJyQiIscSV/BauXIly5Yt47nnnmPZsmXceuutR22zdu1aGhsb2bBhA48//jj33nsvTU1NANTU1PD000/z1FNP8atf/YqHHnqILVu2TOwrkSnFzC7Cf9V3cQTm0vfyg/T/5elJdboJjRMSEZGPMmrwam9vZ/PmzdTW1gJQW1vL5s2b6egYubh53bp1LFmyBNM0KSwspLq6mvXr1wOQnZ2NYRgA9PX1EQ6Hh2+LnCjDk4XvU9/EefJ5DPz51+xf9zPs6OQIORonJCIiH8U52gbBYJDS0lIcDgcADoeDkpISgsEghYWFI7YrLy8fvh0IBGhpaRm+/cILL3DXXXfR2NjIN7/5TebNmzemQouKsse0/YkoLs5J+HPIxLOv/SYHXn6Mzt/9muxohGmfuRHDdKS6LC4vzuEv29up//1uFn1yNpWl+vmKh96H6U89TG/qX2KNGrwmyuWXX87ll19Oc3MzN910ExdddBFz5syJ+/vb27uJRhN3KKm4OId9+w4l7PElwU6/igKHiwOvPE5faADvxddjmKn/7MhfXzibN7a08uPH3uA7f/NxTO3pPS69D9Ofepje1L/xM03juDuLRv3LFAgEaG1txbIsILaIvq2tjUAgcNR2zc2Hx6UEg0HKysqOerzy8nLmz5/Pyy+/HO9rEIlLwUXX4j7nr4ls/x19Lz84KQ475mW5ufYyjRMSEZGYUYNXUVERVVVV1NfXA1BfX09VVdWIw4wAixcvZs2aNUSjUTo6Oti4cSM1NTUA7Nhx+GP1HR0dvP7668ydO3ciX4cIAJ6P1+E+5xoiH/yevpd/jh21Ul0SF8zXOCEREYmJ61DjbbfdxooVK3jggQfIzc1l9erVACxfvpybb76Z+fPnU1dXx1tvvcWiRYsAuOmmm6isrATg8ccf57XXXsPpdGLbNtdddx0XXHBBgl6STHWej18FhsnAn/6LPtvGe+kNKV3zNTRO6JZf/JHHnt/GTdfMT1ktIiKSWoY9mT6Dfxxa4yWj+XAP+998hoE/rsE5ZyHey/4u5Qvun/n9Lp74zU6+es18Pj63OKW1TFZ6H6Y/9TC9qX/jN+41XiLpynPmZ3AvvJbIzj/S9+LPsKOpHeFz5Dih3j6NExIRmYoUvCSjec78NJ5zlxLZ+Sf6Xkht+DpynNATv9U4IRGRqUjBSzKe+4xP4fnE54g0/Jm+jT9NafjSOCERkalNwUumBPeCxXjO+zyRXW/EwpeVuvClcUIiIlOXgpdMGe75NXg++TeD4ev+lIUvjRMSEZm6FLxkSnGffkUsfO3elNLwteCkaSysKqH+97to3t+TkhpERCT5FLxkynGffgWe868jsnsToefvw7bCKanj89Vz8bgc/Mf6LUTT46wuIiIyTgpeMiW5P1aN5/y/xWp8M2XhS+OERESmHgUvmbLcH7sczwVfwGp8i9CGe7EjA0mv4YL5AapmFmickIjIFKHgJVOa+7TL8Fz437H2vE3o+eSHL8Mw+MLieUQsm8ee35bU5xYRkeRT8JIpz111CZ6L/gfWnncIbfhJ0sNXaYGfq86fxRvb9vGXbfuS+twiIpJcCl4igPvUi2Phq+m9lIQvjRMSEZkaFLxEBrlPvRjvUPh67h7sSPLWXI0YJ/QbjRMSEclUCl4iR3CdehHei7+EtXdz0sPX0DihlzbtZXtTZ9KeV0REkkfBS+RDXPMuxHvJ9Vh73ye0/m7scPLC1zUXzaEo18N/rN+qcUIiIhlIwUvkI7jmno/30uVYwS2E1v84aeFL44RERDKbgpfIMbhO+STeS5ZjtWwltP6upIUvjRMSEclcCl4ix+E65ZN4L70Bq2XbYPjqS8rzapyQiEhmUvASGYXr5PPwXvp3sfD17F3YA6GEP6fGCYmIZCYFL5E4uE7+BN7LvoLV+kHSwpfGCYmIZB4FL5E4uU46F+/lX8Fq20Hvs/+W8PClcUIiIplHwUtkDFxzFuK9/H8SbWugd92PsAd6E/p8GickIpJZFLxExsg156/wVv9Povt2JSV8HTlOqKmtO6HPJSIiiaXgJXICXLPPwXvFjUT37ab3mR9h9yfutA9Oh8n/+PSp9PZHuPWXf+T7/98b/O7dIOGIlbDnFBGRxFDwEjlBrlln473iJqLtu2N7vhIYvmYHcvnRjeez9LKTOdQ7wP+uf59/uO81/vOF7bR0JHaPm4iITBzDttPjJEHt7d1Eo4krtbg4h337DiXs8SXxUtXDyK5NhDbeh1k0A/+nv4XhyUro89m2zZbdB3jpzWY2bduHFbWpmlnAJWdN56xTpuF0pO//T+l9mP7Uw/Sm/o2faRoUFWUf834Fr0H6YUt/qexhZPebhJ6/D7NwOv5P/yOG99hvuonU1d3PK28H+c2bzbQf7CM3y82FCwJcfEY50/J9SalhIul9mP7Uw/Sm/o2fglec9MOW/lLdw0jjm4Q23IdZMB3/Z5IXvgCiUZt3G9p5eVMzb+3YDzbMP6mIS86czoKTijBNI2m1jEeqeyjjpx6mN/Vv/BS84qQftvQ3GXoYaXyb0PM/wcwvx/+Zbyc1fA1p7+rjt28189u3m+nqHqAw18NFZ5Rz4YJyCnI8Sa9nLCZDD2V81MP0pv6Nn4JXnPTDlv4mSw8je94mtOEnmPkBfJ/5NqY3JzV1WFHe+mA/L2/ay3u7DmAaBmedMo1LzppO1awCTGPy7QWbLD2UE6cepjf1b/wUvOKkH7b0N5l6GNnzDqEN92DmBfDVpi58DWk90Mtv3mzm1beDdIfClOT7uPiscs6fHyDX705pbUeaTD2UE6Mepjf1b/wUvOKkH7b0N9l6GGl6l9Bz92Dmlcb2fPlyU10S4YjFG1v38fKmvWxr6sLpMDhnXgmXnDWdUyryMFK8F2yy9VDGTj1Mb+rf+Cl4xUk/bOlvMvYw0vQeoefuxswtje35mgTha8jefd28/GYzv3s3SKjfonxaFpecWc4nTy/D73WlpKbJ2EMZG/Uwval/46fgFSf9sKW/ydrDyN7NhNbfjZk7Dd9nvoPpz0t1SSP0D1j88f1WXn5zLw3BQ7idJgtPK+XSs6YzO5DcoDhZeyjxUw/Tm/o3fgpecdIPW/qbzD2MNL9P6NkfT9rwNWRXy0Fe3tTMHza3MBCOMrMsh0vPms7CqhK8bmfCn38y91Diox6mN/Vv/BS84qQftvQ32XsYaX6f0PofY2ZPix129OenuqRj6u2L8IfNLby0aS979/Xg8zg472NlXHLmdCpKEneKjMneQxmdepiebNumrTPEgG1Q4HOS7UvNcoNMoOAVJ/2ySH/p0MNI8xZC6+/CzC7CV/udSR2+IPbLeMfeg7y0aS9/2tJGxIpyckUel545nXNOLcbldEzo86VDD+X41MP0YNs2wfZetu7pZNueTrY2HqCze2D4/vJpWcytyOOUynzmVuRTlOdNYbXpRcErTvplkf7SpYeR4FZCz96FkVWAv/Y7mFkFqS4pLt2hMK+9E+TlTXtpPRAiy+vkggUBLj5zOmWF/gl5jnTpoRybejg5RW2b5n09bB0MWdv2dHKwNwxAXrabeZX5zJtRwNxZhby5pZVte7r4YG8noX4LgKJcz3AIO6Uyn/Iif8o/BT1ZKXjFSb8s0l869TDSsi0Wvvx5+GtXpE34gmMP6b70rOmcOc4h3enUQ/lo6uHkEI3a7GnrZmvjgeG9Wj19EQAKcz3DQWteZT4lBb7hEHVk/6JRm6Z93Wzb08m2pi627+mkqye2Vyzb5+KUijxOqchnbmU+M0qzx/XezyQKXnHSL4v0l249jLRsJ/Tsv6Vl+Bry4SHdeVluLjwjwEVnlDMtb+xDutOth3I09TA1IlaU3a2HBg8bdrK9qYtQfyxoFed7mVdZwLwZ+cyrzGda/rHfm8fr39A6sG2DQW77ni7aOkMAeFwO5pTnMrcyn7kVecyZnofHNbFLEdKFglec9Msi/aVjD62W7fQ++28YvrzYYcfswlSXdEKOOaT7rOksmBP/kO507KGMpB4mR8SK0hA8yNbGTrbu6eSDpi76w7HDgmWFfuZW5g8HrcLc+NdnjbV/nd39wyFsW1MnTW3d2IDDNJhZljN4aDK2Z2yqLNhX8IqTflmkv3TtodX6Ab3r/g3DlzMYvopSXdK4fNSQ7ovPKOfCM8rJzz7+kO507aEcph4mRjhisWPvweHDhjv2djEQiQIwfVoWcwdD1rzKfPJGeZ8dz3j719sX5oO9XWwbDGK7ggeJWLG/3dOLs4aD2NyKsQXCdKLgFSf9skh/6dxDq20Hvc/8CMObjf/KFWkfvuDoId0O0+DMoSHdMz96SHc691Bi1MOJ0T9g8UFzF1sbO9nWeICdgwHGACpLsoeD1tzKfHImcN7qRPcvHLHY2XxweI3YB3u76BuI7ZmblucdXCOWx9zKfMoKM2PBvoJXnPTLIv2lew+ttp30rvtXDE92bM9XzrRUlzRhjhrSXeDjkjOnc/78shF/NNK9h5LZPRz6c5mIcBDqj7C9qYutew6wrbGTXS2HsKI2hgEzS3MGDxsWcEplHlkJHOmV6P5Z0ShNbT2DC/Y72X7Epytz/K5YEBs8jcWM0mwcZvot2FfwilMm/7KYKjKhh4fDV9Zg+CpOdUkT6iOHdJ9awiVnxoZ0l5Tkpn0Pp7pMeB8C2FGLaGeQ6P7dWO2Nw5cM9ILDCQ4XhsMFg/+GrhvOwa+ZzuHrh7dzDl8P2w7aDoYJdg6wt2OAlq4wYduBZTgoLsxhelkBM8oLmBEowOvzjnwc05GwPUPJ7p9t27QeCA2uE4uFsX2dfQB43A5OLs8dPo3FnPJc3GmwYH9CgldDQ6oyMpAAABWJSURBVAMrVqygs7OT/Px8Vq9ezaxZs0ZsY1kWd955J6+88gqGYXDDDTewZMkSAO6//37WrVuHaZq4XC6+8Y1vcOGFF47phSh4yWgypYfWvgZ6n/lXDLcvdtgxw8LXkA8P6Z4+LYuFpwfwu0ym5XkpyvNSlOvF50n8qCKZOOn4PrQj/UQ7mrD27ya6vxGrfTfRjiawYnticLgwCytxTJuB4csDK4xthQcvI7Hthr4WGbovMnK7yADRSBgjGmb8kcmIBTCnC8N0xi5HhMAPBUOnC8N0HX+7wZCYV5DDwYOho5/vI68fffPo+4/3aj962+7eAZr29dC0r5umfT3s7wwRxcBhxj44UFGczfSSbCqKs/G6Hcd9rKOe0eHELJ6T0EOaExK8vvCFL/DZz36Wuro6nnrqKZ544gkefvjhEds8+eSTrF27lgcffJDOzk6uvvpqHnvsMSoqKnjllVc455xz8Pl8bNmyheuuu45XX30Vrzf+hXUKXjKaTOqhtX9XLHy5vLFTTeRmZviCw0O6f/tWM41t3YQHFwwPyfa5KMr1Hg5jeYPXc71My/Ph9yqYTSaT/X1o9/fEAlb7bqz9jUTbdxPtDMLQn0K3H8e0mZhFMwYvZ2Lml2GYY9vT0tXdP3iy0thi+L37e2IP7zQ4pTyHU6dnM3d6FjOneXEa0SOCXCy8EQ1jR8IjwhtW5IggFz4i8H0o/B35PZEPfy1yOFBOUd7qG3HNWZiwxx938Gpvb6empobXX38dh8OBZVmce+65bNiwgcLCwx99v+GGG7jmmmtYvHgxALfffjvl5eVcf/31Ix7Ptm3OOeccnnnmGcrKyuJ+IQpeMppM66G1fze9z/wQw+mJ7fnKLUl1SQlXVJTNjt3ttHf1sb+rj/aDscv9XSHau/po7+ob/iTXEJ/HybQRYWwonPkoyvOS5XVmxILddDFZ3oe2bWP3HBgRsKz9u7G724e3MbIKRgQsx7QZGNnTTujnpeNg33DQ2rqnk9aOXiB2uOyU6XnDp3eYHchN+YlGbduGaORwgItGhgNafq6bzgM9x/rODz/QaE90rO8c22N96L5IxCLY3kvTvm727OumeX8PA+HY74W8LDeVJVlUFGdTUZxFQY5nZD9NB47SUzASuHZstOA16v8qBoNBSktLcThiad/hcFBSUkIwGBwRvILBIOXl5cO3A4EALS0tRz3ek08+yYwZM8YUukSmIse0mfg/8216n/khvWv/ZcLCl23bsV9k0QjYUYha2FFr+DrRwa/Zh69jW9jRaOx7olGwrcHvO3x9+PsGtx/azj7iPgafxz7i+vD3RC32+314IwbTnW4qXB4Mnxty3BizPOD0gCOPUNRBVx8cCNm099js77bY123RcqCHzbsP0D/4iakhHrdjRCgbCmRDX8vxuxTM0pxtR7G7Wgf3ZDUOX9p9QwHQwMgrxVFyEuZplw3v0TJ9uSf4fDb7u/oGQ9YBtjZ2sr8rti7J53FwSkU+F50RYF5lATPLJt8CccMwDh9u/NAHIr3FOThcqQ/Ox+MEZs+A2YO3rWiUPW3dsVNY7OnkhaZODm0PA53kDi7YP6Uy9unJypLshIaueCR1H/0f//hH7rnnHn75y1+O+XuPlx4nSnFxTsKfQxIr43pYfDr9hbcTfPQ2+tZ+H3fZbIgeDi6HL6PY0cjhMGRFhkORbVlHbZ8yhhlbV2KasUM3puOIS5NQNIod7o/9iwx89EMA+YP/Zn/4zjwnhtND1OHGMpyEcdIfdRKyTHq7TLr3GfRGTFpxssd2MmA7iZouvH4f3qwssnOyyMnNITcvm4KCHAqL8sjNzcHp8WK4PBguN4Yxuf6ITkaJfB/akTAD+/bQ37qTgZYG+lsbGGjdjR2OBR9MJ+7iSvzz/gp36Ww8ZXNwl87EdI8+ScG2bfrDFr19EXpCYXr6wvSEwvSGInT3hekNhdkVPMi7O9vZP3jG9hy/i4/NKaLu4mmcflIRs8vzcMR5wuDJKh1/j5aV5vFX86cDsT42tXWzuaGd93a2815DB29s2weA3+vktuvPo2p26k5WPWrwCgQCtLa2YlnW8KHGtrY2AoHAUds1NzezYMEC4Og9YJs2beIf//EfeeCBB5gzZ86YC9WhRhlNxvbQLML76W/T/7tH6O86cDisGCaYLnB6Y4FmMMBgmmA6MI3D1xm8bpix0BO7HQs7Q9eHtj382IPbHPk4g/cZR1zHdMYeZ8TXjn4cDHPUPUtH9tC2o7HDH5F+iPRjhwdil5EjLwcO3x8ZgPDIr3sjA2R/aBt7oJ9opB8jMoBhD4bQKHBo8F/z4XqGvnQky3BiO9wYTjemy4PDHQtlON0YzqFLNzg9g5fuwfs9sfDmycbwZGF4szG82eDyZdQet4l8H9oDodgnCof3Yu0meqD58P88uLw4imbgnHsBjmkzobCSPl8pXREI9UXo7Y/QuztCaNseevsjhAb/9fYNXg7+G9o21B/BGuXvTK7fxdzKfGr+qpJ5lfmUF2eNOCddR3v3hLz2VMmU36NeEz5+UhEfPyl2TsSOg31sa+pkT1s3diSS0Nc47kONRUVFVFVVUV9fT11dHfX19VRVVY04zAiwePFi1qxZw6JFi+js7GTjxo08+uijALz99tt84xvf4Cc/+Qkf+9jHxvmSRKYeR1El/iu/m+oyksowTHDFwkqi2ENrWyL9w2Gtv7eXroPddB/softQD709PYR6QwyEegn392GHB3AbEdxGBBcRPKZFlrMbnyOK14zgNiychHFEwxjRAYzR1sEYDgxv1ohAhic79jVv9lFBzfAMXjoya/yK1ds1uPdqF9H2RowDjTh79w/fP+DMostdSkf2QtqMIoLRabSEswi1ReltDBPqt+gP7wR2Hvd5PG4Hfo8Tv8eJz+Mk1++mrNCPb/hrDvxeV+zS48TvcY34mseVuFM5SOIU5nr5xGllfOK0VFcS56cad+zYwYoVKzh48CC5ubmsXr2aOXPmsHz5cm6++Wbmz5+PZVncfvvtvPbaawAsX76cpUuXAvDZz36WvXv3UlpaOvyYP/zhD5k3b17chWqPl4xGPUx/6dDD/rAVW+j/EQv/9x/so6v7yEOkNi7DpiTHQWmOg0K/jZc+vHYfnmgfXjuEx+7HHQ3hiYZwR0O4o324rNh1hx05Zh2W4SLi9BNx+gYv/VhOP5br8GXUlTX4z4ftzsJ2+TFME9MwMAwjtvPTMAZvg2kYmObh68PbMPLrI7c5YlsD/NlemoJdw3uShvYsDe9p6gtjhjrI7guS199KUXQfpfZ+8sze4de238pmr1VIU6SQpsHLg7YPh2ni9zqPCEnOEbc/6ms+jxOf93CommzrrSabdHgPTnY6gWqc9MOW/tTD9JcJPQxHLNoP9g9+MjM04tOZh3oGiNp27HMH2ESjduxzDvbgZdQe/Hrsa047jM/ux2/04TP6yTL6yTL78Q9eZhn9+I2B2OURt03jo39XRm0I2W56bA+9toeeqOcjrruP+voATj7ihE2jMolS6uhiuqODCmcHM1wHKDc78BmxcBrF4KCziEOeMnqzAgzkTMfKq8CTlRMLSt6RgcrlHP1wtYxPJrwHU23chxpFRCR+LqeDskI/ZYX+CX1c2z4ypB0OZ7ZtEx36etQmGo1iDfQS7evG7u+B/m7o646dcb2/G0d/D3kDPeQP9GCEezAHOjEGejCt/mM+d9RwEnX5iDizBvemDe5lc/gJO2LXww4flulmmrMbZ+cefD3NuA4FMaJDJyF1YxZV4Ciqwpw2E0fRDMzCCvKcEzdnUCQdKHiJiKQBY+iwXlx7nnzA2Aat21YYu78HezCwxS67Y5d93dDfc/h2/wHsg3uw+3pipw75sKGTkM64bFwnIRXJRApeIiKC4XBh+PPBnx/399i2DeG+wUDWgz3Qy7RZszkw4NUhQZFjUPASEZETYhgGuH0Ybh8MzhR15edgaI2QyDHp4x0iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkCl4iIiIiSaLgJSIiIpIkcQWvhoYGli5dSk1NDUuXLmXXrl1HbWNZFqtWraK6uporrriCNWvWDN/36quvcs0113D66aezevXqCSteREREJJ3EFbxWrlzJsmXLeO6551i2bBm33nrrUdusXbuWxsZGNmzYwOOPP869995LU1MTAJWVlXzve9/jy1/+8sRWLyIiIpJGRg1e7e3tbN68mdraWgBqa2vZvHkzHR0dI7Zbt24dS5YswTRNCgsLqa6uZv369QDMnDmTqqoqnE5nAl6CiIiISHoYNQkFg0FKS0txOBwAOBwOSkpKCAaDFBYWjtiuvLx8+HYgEKClpWXCCi0qyp6wxzqW4uKchD+HJJZ6mP7Uw/SnHqY39S+x0mYXVHt7N9GonbDHLy7OYd++Qwl7fEk89TD9qYfpTz1Mb+rf+JmmcdydRaMeagwEArS2tmJZFhBbRN/W1kYgEDhqu+bm5uHbwWCQsrKyE61bREREJOOMGryKioqoqqqivr4egPr6eqqqqkYcZgRYvHgxa9asIRqN0tHRwcaNG6mpqUlM1SIiIiJpKK5PNd5222088sgj1NTU8Mgjj7Bq1SoAli9fzjvvvANAXV0dFRUVLFq0iGuvvZabbrqJyspKAP785z9z0UUX8dBDD/Gf//mfXHTRRbzyyisJekkiIiIik5Nh23biFk5NIK3xktGoh+lPPUx/6mF6U//Gb9xrvERERERkYih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIkih4iYiIiCSJgpeIiIhIksQVvBoaGli6dCk1NTUsXbqUXbt2HbWNZVmsWrWK6upqrrjiCtasWRPXfSIiIiJTRVzBa+XKlSxbtoznnnuOZcuWceuttx61zdq1a2lsbGTDhg08/vjj3HvvvTQ1NY16n4iIiMhU4Rxtg/b2djZv3sxDDz0EQG1tLXfccQcdHR0UFhYOb7du3TqWLFmCaZoUFhZSXV3N+vXruf766497X7xM0ziBlzc2yXgOSSz1MP2ph+lPPUxv6t/4jPbfb9TgFQwGKS0txeFwAOBwOCgpKSEYDI4IXsFgkPLy8uHbgUCAlpaWUe+LV0FB1pi2PxFFRdkJfw5JLPUw/amH6U89TG/qX2Jpcb2IiIhIkowavAKBAK2trViWBcQWyre1tREIBI7arrm5efh2MBikrKxs1PtEREREpopRg1dRURFVVVXU19cDUF9fT1VV1YjDjACLFy9mzZo1RKNROjo62LhxIzU1NaPeJyIiIjJVGLZt26NttGPHDlasWMHBgwfJzc1l9erVzJkzh+XLl3PzzTczf/58LMvi9ttv57XXXgNg+fLlLF26FOC494mIiIhMFXEFLxEREREZPy2uFxEREUkSBS8RERGRJFHwEhEREUkSBS8RERGRJFHwIr4h4DJ5HThwgOXLl1NTU8OVV17JV7/6VTo6OlJdlpyA++67j3nz5rFt27ZUlyJj1N/fz8qVK1m0aBFXXnklt9xyS6pLkjF66aWXuPrqq6mrq+Oqq65iw4YNqS4pI+lTjcAXvvAFPvvZz1JXV8dTTz3FE088wcMPP5zqsiROnZ2dbN26lXPPPReA1atX09XVxfe///0UVyZj8d577/HjH/+YnTt38rOf/Yy5c+emuiQZgzvvvBPTNPnud7+LYRjs37+fadOmpbosiZNt2yxcuJBHH32UuXPnsmXLFj7/+c/zxhtvYJraRzORpvx/zaEh4LW1tUBsCPjmzZu1xySN5OfnD4cugDPPPHPEpASZ/AYGBrj99tu57bbbUl2KnICenh6efPJJvva1r2EYsQHBCl3pxzRNDh06BMChQ4coKSlR6EqAUYdkZ7p4h4BLeohGo/zqV7/isssuS3UpMgb33HMPV111FRUVFakuRU7Anj17yM/P57777uP1118nKyuLr33ta5xzzjmpLk3iZBgGd999NzfeeCN+v5+enh5+/vOfp7qsjKQoKxnljjvuwO/3c91116W6FInTpk2bePfdd1m2bFmqS5ETZFkWe/bs4bTTTuPXv/413/rWt/j7v/97uru7U12axCkSifDv//7vPPDAA7z00kv89Kc/5etf/zo9PT2pLi3jTPngFe8QcJn8Vq9eze7du7n77ru1ezyN/OlPf2LHjh1cfvnlXHbZZbS0tPDlL3+ZV199NdWlSZwCgQBOp3N4ycYZZ5xBQUEBDQ0NKa5M4vX+++/T1tbG2WefDcDZZ5+Nz+djx44dKa4s80z5v07xDgGXye2uu+7i3Xff5f7778ftdqe6HBmDG264gVdffZUXX3yRF198kbKyMn7xi19wwQUXpLo0iVNhYSHnnnvu8DzehoYG2tvbmTlzZoork3iVlZXR0tLCzp07gdiM5vb2dmbMmJHiyjKPPtXIsYeAS3rYvn07tbW1zJo1C6/XC0BFRQX3339/iiuTE3HZZZfpU41paM+ePfzTP/0TnZ2dOJ1Ovv71r3PxxRenuiwZg6effpoHH3xw+AMSN998M9XV1SmuKvMoeImIiIgkyZQ/1CgiIiKSLApeIiIiIkmi4CUiIiKSJApeIiIiIkmi4CUiIiKSJApeIiIiIkmi4CUiIiKSJApeIiIiIkny/wP8N5i7aFkRDwAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 720x360 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"UQK8JOo9Y1ch"},"source":["#### 1.3.5.1 Improve loss by varying nodes and hidden layers\n","\n","Take your former model as a starting point and now either add nodes or layers to see if the model improves"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Jq3LsRsX_hG","executionInfo":{"status":"ok","timestamp":1627942138993,"user_tz":420,"elapsed":1480,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"88df2ba4-b509-42fa-ad08-42db20c18254"},"source":["model = keras.Sequential([\n","    ### YOUR CODE HERE ###\n","    # make more or less layers (layers.Dense())\n","    # make more or less units (layers.Dense(512))\n","    layers.Dense(32),\n","    layers.Dense(16),\n","    layers.Dense(1),\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='mse',\n",")\n","\n","history = model.fit(\n","    X_train_std, y_train_std,\n","    validation_data=(X_val_std, y_val_std),\n","    batch_size=256,\n","    epochs=10,\n",")"],"execution_count":70,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","15/15 [==============================] - 1s 11ms/step - loss: 3.0090 - val_loss: 1.9299\n","Epoch 2/10\n","15/15 [==============================] - 0s 4ms/step - loss: 1.3536 - val_loss: 0.7737\n","Epoch 3/10\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4739 - val_loss: 0.2300\n","Epoch 4/10\n","15/15 [==============================] - 0s 4ms/step - loss: 0.1334 - val_loss: 0.0781\n","Epoch 5/10\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0592 - val_loss: 0.0471\n","Epoch 6/10\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0354\n","Epoch 7/10\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0325\n","Epoch 8/10\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0311 - val_loss: 0.0305\n","Epoch 9/10\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0288\n","Epoch 10/10\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0271\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fBUTNwgr52Hf","executionInfo":{"status":"ok","timestamp":1627942142845,"user_tz":420,"elapsed":152,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"556fffaa-e150-4924-a846-4c3e6cad6c00"},"source":["model.predict(X_train_std[0].reshape(1, -1))"],"execution_count":71,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f942b0e0c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([[1.7205572]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":71}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KzGmq6KH38E-","executionInfo":{"status":"ok","timestamp":1627941701208,"user_tz":420,"elapsed":198,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"c27844c4-5d8f-41cf-d7fd-0cce84515801"},"source":["[list(i.shape) for i in model.trainable_variables]"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[13, 512],\n"," [512],\n"," [512, 512],\n"," [512],\n"," [512, 256],\n"," [256],\n"," [256, 128],\n"," [128],\n"," [128, 1],\n"," [1]]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"G4kGMGOcZF7S","executionInfo":{"status":"ok","timestamp":1623034748591,"user_tz":300,"elapsed":408,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"e2276665-1c6f-40e3-a7b4-e20287946df9"},"source":["y_pred = model.predict(X_test_std)\n","plt.plot(np.exp(y_test_std), np.exp(y_pred), ls='', marker='o')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7f5d26303e10>]"]},"metadata":{"tags":[]},"execution_count":18},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"FsUB7TTLZpS-"},"source":["#### 1.3.5.2 Learning Curves\n","\n","Using 4 hidden layers now create 4 models that run for 30 epochs each:\n","\n","1. Vary the number of nodes in each layer\n","2. Record the train/val/test score (MSE)\n","3. Plot either total nodes or total trainable parameters vs score for each of the 5 models"]},{"cell_type":"code","metadata":{"id":"e-ktlZkZwmxL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627942957189,"user_tz":420,"elapsed":12762,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"62b20521-be65-49ae-90bb-0dafb80f6598"},"source":["# Code Cell for Exercise 1.3.5\n","perf = []\n","\n","for nodes in [1,2,3,4]:\n","\n","  model = keras.Sequential([\n","      ### YOUR CODE HERE ###\n","      # make more or less layers (layers.Dense())\n","      # make more or less units (layers.Dense(512))\n","      layers.Dense(2**nodes),\n","      layers.Dense(4**nodes),\n","      layers.Dense(2**nodes),\n","      layers.Dense(1),\n","  ])\n","\n","  model.compile(\n","      optimizer='adam',\n","      loss='mse',\n","  )\n","\n","  history = model.fit(\n","      X_train_std, y_train_std,\n","      validation_data=(X_val_std, y_val_std),\n","      batch_size=256,\n","      epochs=30,\n","  )\n","\n","  mse_test = mean_squared_error(y_test_std, model.predict(X_test_std))\n","  mse_val = mean_squared_error(y_val_std, model.predict(X_val_std))\n","  mse_train = mean_squared_error(y_train_std, model.predict(X_train_std))\n","\n","  tot_nodes = nodes**2 + nodes**4 + nodes**2 + 1\n","  perf.append([tot_nodes, mse_test, mse_val, mse_train])"],"execution_count":79,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","15/15 [==============================] - 1s 12ms/step - loss: 3.9522 - val_loss: 3.6952\n","Epoch 2/30\n","15/15 [==============================] - 0s 3ms/step - loss: 3.4567 - val_loss: 3.2568\n","Epoch 3/30\n","15/15 [==============================] - 0s 4ms/step - loss: 3.0778 - val_loss: 2.9197\n","Epoch 4/30\n","15/15 [==============================] - 0s 4ms/step - loss: 2.7771 - val_loss: 2.6515\n","Epoch 5/30\n","15/15 [==============================] - 0s 3ms/step - loss: 2.5319 - val_loss: 2.4189\n","Epoch 6/30\n","15/15 [==============================] - 0s 3ms/step - loss: 2.3151 - val_loss: 2.2132\n","Epoch 7/30\n","15/15 [==============================] - 0s 3ms/step - loss: 2.1210 - val_loss: 2.0251\n","Epoch 8/30\n","15/15 [==============================] - 0s 4ms/step - loss: 1.9411 - val_loss: 1.8502\n","Epoch 9/30\n","15/15 [==============================] - 0s 3ms/step - loss: 1.7710 - val_loss: 1.6831\n","Epoch 10/30\n","15/15 [==============================] - 0s 4ms/step - loss: 1.6067 - val_loss: 1.5215\n","Epoch 11/30\n","15/15 [==============================] - 0s 3ms/step - loss: 1.4479 - val_loss: 1.3643\n","Epoch 12/30\n","15/15 [==============================] - 0s 5ms/step - loss: 1.2935 - val_loss: 1.2125\n","Epoch 13/30\n","15/15 [==============================] - 0s 3ms/step - loss: 1.1447 - val_loss: 1.0665\n","Epoch 14/30\n","15/15 [==============================] - 0s 4ms/step - loss: 1.0016 - val_loss: 0.9271\n","Epoch 15/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.8655 - val_loss: 0.7955\n","Epoch 16/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.7379 - val_loss: 0.6731\n","Epoch 17/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.6199 - val_loss: 0.5610\n","Epoch 18/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.5126 - val_loss: 0.4599\n","Epoch 19/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.4167 - val_loss: 0.3707\n","Epoch 20/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3331 - val_loss: 0.2933\n","Epoch 21/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2612 - val_loss: 0.2285\n","Epoch 22/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.2019 - val_loss: 0.1753\n","Epoch 23/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1539 - val_loss: 0.1331\n","Epoch 24/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1164 - val_loss: 0.1005\n","Epoch 25/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0881 - val_loss: 0.0763\n","Epoch 26/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0675 - val_loss: 0.0594\n","Epoch 27/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0477\n","Epoch 28/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0398\n","Epoch 29/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0345\n","Epoch 30/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0330 - val_loss: 0.0309\n","Epoch 1/30\n","15/15 [==============================] - 1s 11ms/step - loss: 3.8468 - val_loss: 2.9711\n","Epoch 2/30\n","15/15 [==============================] - 0s 3ms/step - loss: 2.6186 - val_loss: 2.1578\n","Epoch 3/30\n","15/15 [==============================] - 0s 4ms/step - loss: 1.9456 - val_loss: 1.6623\n","Epoch 4/30\n","15/15 [==============================] - 0s 3ms/step - loss: 1.5008 - val_loss: 1.2739\n","Epoch 5/30\n","15/15 [==============================] - 0s 4ms/step - loss: 1.1348 - val_loss: 0.9332\n","Epoch 6/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.8145 - val_loss: 0.6434\n","Epoch 7/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.5518 - val_loss: 0.4205\n","Epoch 8/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3579 - val_loss: 0.2650\n","Epoch 9/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.2267 - val_loss: 0.1686\n","Epoch 10/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.1471 - val_loss: 0.1133\n","Epoch 11/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1013 - val_loss: 0.0822\n","Epoch 12/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0748 - val_loss: 0.0640\n","Epoch 13/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0585 - val_loss: 0.0523\n","Epoch 14/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0479 - val_loss: 0.0446\n","Epoch 15/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0408 - val_loss: 0.0391\n","Epoch 16/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0350\n","Epoch 17/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0317\n","Epoch 18/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0293 - val_loss: 0.0294\n","Epoch 19/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0276\n","Epoch 20/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0261\n","Epoch 21/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0249\n","Epoch 22/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0240\n","Epoch 23/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0223 - val_loss: 0.0232\n","Epoch 24/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0216 - val_loss: 0.0225\n","Epoch 25/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0219\n","Epoch 26/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0215\n","Epoch 27/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0201 - val_loss: 0.0210\n","Epoch 28/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0198 - val_loss: 0.0207\n","Epoch 29/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0195 - val_loss: 0.0204\n","Epoch 30/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0193 - val_loss: 0.0202\n","Epoch 1/30\n","15/15 [==============================] - 1s 11ms/step - loss: 3.2130 - val_loss: 1.5809\n","Epoch 2/30\n","15/15 [==============================] - 0s 3ms/step - loss: 1.0188 - val_loss: 0.5215\n","Epoch 3/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.3511 - val_loss: 0.2228\n","Epoch 4/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1840 - val_loss: 0.1525\n","Epoch 5/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.1324 - val_loss: 0.1129\n","Epoch 6/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0962 - val_loss: 0.0850\n","Epoch 7/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0741 - val_loss: 0.0673\n","Epoch 8/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0596 - val_loss: 0.0548\n","Epoch 9/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0491 - val_loss: 0.0461\n","Epoch 10/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0415 - val_loss: 0.0397\n","Epoch 11/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0361 - val_loss: 0.0348\n","Epoch 12/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0319 - val_loss: 0.0312\n","Epoch 13/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0287\n","Epoch 14/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0265 - val_loss: 0.0265\n","Epoch 15/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0248\n","Epoch 16/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0233 - val_loss: 0.0236\n","Epoch 17/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0225\n","Epoch 18/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0213 - val_loss: 0.0216\n","Epoch 19/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0209\n","Epoch 20/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0204\n","Epoch 21/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0200\n","Epoch 22/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0192 - val_loss: 0.0198\n","Epoch 23/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0189 - val_loss: 0.0194\n","Epoch 24/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0190\n","Epoch 25/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0183 - val_loss: 0.0188\n","Epoch 26/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0185\n","Epoch 27/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0180 - val_loss: 0.0185\n","Epoch 28/30\n","15/15 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0185\n","Epoch 29/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0181\n","Epoch 30/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0181\n","Epoch 1/30\n","15/15 [==============================] - 1s 11ms/step - loss: 1.3760 - val_loss: 0.1328\n","Epoch 2/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.1458 - val_loss: 0.0847\n","Epoch 3/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0627 - val_loss: 0.0560\n","Epoch 4/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0402 - val_loss: 0.0340\n","Epoch 5/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0287 - val_loss: 0.0255\n","Epoch 6/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0239 - val_loss: 0.0233\n","Epoch 7/30\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0216 - val_loss: 0.0216\n","Epoch 8/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0200\n","Epoch 9/30\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0188 - val_loss: 0.0187\n","Epoch 10/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0184\n","Epoch 11/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0187\n","Epoch 12/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0180\n","Epoch 13/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0183\n","Epoch 14/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0184\n","Epoch 15/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0176 - val_loss: 0.0173\n","Epoch 16/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0179\n","Epoch 17/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0189\n","Epoch 18/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0179 - val_loss: 0.0181\n","Epoch 19/30\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0178 - val_loss: 0.0174\n","Epoch 20/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0179 - val_loss: 0.0179\n","Epoch 21/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0198\n","Epoch 22/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0182 - val_loss: 0.0183\n","Epoch 23/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0192\n","Epoch 24/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0177 - val_loss: 0.0175\n","Epoch 25/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0184 - val_loss: 0.0231\n","Epoch 26/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0176\n","Epoch 27/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0193\n","Epoch 28/30\n","15/15 [==============================] - 0s 5ms/step - loss: 0.0187 - val_loss: 0.0185\n","Epoch 29/30\n","15/15 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0181\n","Epoch 30/30\n","15/15 [==============================] - 0s 6ms/step - loss: 0.0177 - val_loss: 0.0194\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"GXwT2c257NOM","executionInfo":{"status":"ok","timestamp":1627943015780,"user_tz":420,"elapsed":142,"user":{"displayName":"Wesley Beckner","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gis2tewog0nYcz7REtNxkAs58_fKdVn5wvb3mXkPQ=s64","userId":"17051665784581118920"}},"outputId":"fb190039-a812-4916-bde2-40d05abccfe4"},"source":["df = pd.DataFrame(perf)\n","df.columns = ['tot. units', 'test mse', 'val mse', 'train mse']\n","df"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tot. units</th>\n","      <th>test mse</th>\n","      <th>val mse</th>\n","      <th>train mse</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>0.030658</td>\n","      <td>0.030919</td>\n","      <td>0.031088</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25</td>\n","      <td>0.020217</td>\n","      <td>0.020164</td>\n","      <td>0.019062</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>100</td>\n","      <td>0.017429</td>\n","      <td>0.018110</td>\n","      <td>0.017416</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>289</td>\n","      <td>0.019124</td>\n","      <td>0.019371</td>\n","      <td>0.018190</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   tot. units  test mse   val mse  train mse\n","0           4  0.030658  0.030919   0.031088\n","1          25  0.020217  0.020164   0.019062\n","2         100  0.017429  0.018110   0.017416\n","3         289  0.019124  0.019371   0.018190"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"markdown","metadata":{"id":"EHJ1vrnFexQ8"},"source":["When we look at our historical loss do we notice that sometimes before the last epoch we actually hit a minimum? We'll discuss how to deal with this in the next session!"]}]}